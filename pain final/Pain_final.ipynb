{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping,ReduceLROnPlateau\n",
    "from tensorflow.python.keras.layers.normalization import BatchNormalization\n",
    "from tensorflow.python.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "\n",
    "from tensorflow.python.keras.utils.generic_utils import get_custom_objects\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "def hourglass_network(input_shape, num_classes, num_stacks, num_channels):\n",
    "    \n",
    "    input = Input(input_shape)\n",
    "\n",
    "    start = front_module(input, num_channels)\n",
    "\n",
    "    head_next_stage = start\n",
    "\n",
    "    outs = []\n",
    "    for i in range(num_stacks):\n",
    "        head_next_stage, head_to_loss = hourglass_module(head_next_stage, num_classes, num_channels, i)\n",
    "        outs.append(head_to_loss)\n",
    "    \n",
    "    x = Flatten()(outs[-1])\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(num_classes, activation=None, name='Predictions')(x)\n",
    "\n",
    "    model = Model(inputs=input, outputs=x)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def hourglass_module(bottom, num_classes, num_channels, hgid):\n",
    "\n",
    "    left_features = left_half_blocks(bottom, hgid, num_channels)\n",
    "\n",
    "    rf1 = right_half_blocks(left_features, hgid, num_channels)\n",
    "    \n",
    "    head_next_stage, head_parts = heads(bottom, rf1, num_classes, hgid, num_channels)\n",
    "\n",
    "    return head_next_stage, head_parts\n",
    "\n",
    "def front_module(input, num_channels):\n",
    "    \n",
    "    x = Conv2D(64,kernel_size=(7, 7), strides=(2, 2), padding='same', activation='relu', name='front_conv_1x1_x1')(\n",
    "        input)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = bottleneck_block(x, int(num_channels // 2), 'front_residual_x1')\n",
    "    x = MaxPool2D(pool_size=(2, 2), strides=(2, 2))(x)\n",
    "    x = bottleneck_block(x, int(num_channels // 2), 'front_residual_x2')\n",
    "    x = bottleneck_block(x, num_channels, 'front_residual_x3')\n",
    "\n",
    "    return x\n",
    "\n",
    "def heads(prelayerfeatures, rf1, num_classes, hgid, num_channels):\n",
    "    \n",
    "    head = Conv2D(num_channels, kernel_size=(1, 1), activation='relu', padding='same', name=str(hgid) + 'conv_1x1_x1')(\n",
    "        rf1)\n",
    "    head = BatchNormalization()(head)\n",
    "\n",
    "    head_parts = Conv2D(num_classes, kernel_size=(1, 1), activation='linear', padding='same',\n",
    "                        name=str(hgid) + 'conv_1x1_parts')(head)\n",
    "\n",
    "    head = Conv2D(num_channels, kernel_size=(1, 1), activation='linear', padding='same',\n",
    "                  name=str(hgid) + 'conv_1x1_x2')(head)\n",
    "    head_m = Conv2D(num_channels, kernel_size=(1, 1), activation='linear', padding='same',\n",
    "                    name=str(hgid) + 'conv_1x1_x3')(head_parts)\n",
    "\n",
    "    head_next_stage = Add()([head, head_m, prelayerfeatures])\n",
    "    return head_next_stage, head_parts\n",
    "\n",
    "\n",
    "def bottleneck_block(bottom, num_out_channels, block_name):\n",
    "\n",
    "    if K.int_shape(bottom)[-1] == num_out_channels:\n",
    "        skip = bottom\n",
    "    else:\n",
    "        skip = Conv2D(num_out_channels, kernel_size=(1, 1), activation='relu', padding='same',\n",
    "                       name=block_name + 'skip')(bottom)\n",
    "\n",
    "    x = Conv2D(int(num_out_channels / 2), kernel_size=(1, 1), activation='relu', padding='same',\n",
    "                name=block_name + 'conv_1x1_x1')(bottom)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(int(num_out_channels / 2), kernel_size=(3, 3), activation='relu', padding='same',\n",
    "                name=block_name + 'conv_3x3_x2')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(num_out_channels, kernel_size=(1, 1), activation='relu', padding='same',\n",
    "                name=block_name + 'conv_1x1_x3')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Add(name=block_name + 'residual')([skip, x])\n",
    "\n",
    "    return x\n",
    "\n",
    "def left_half_blocks(bottom, hglayer, num_channels):\n",
    "\n",
    "    hgname = 'hg' + str(hglayer)\n",
    "\n",
    "    f1 = bottleneck_block(bottom, num_channels, hgname + 'l1')\n",
    "    x = MaxPool2D(pool_size=(2, 2), strides=(2, 2))(f1)\n",
    "\n",
    "    f2 = bottleneck_block(x, num_channels, hgname + 'l2')\n",
    "    x = MaxPool2D(pool_size=(2, 2), strides=(2, 2))(f2)\n",
    "\n",
    "    f4 = bottleneck_block(x, num_channels, hgname + 'l4')\n",
    "    x = MaxPool2D(pool_size=(2, 2), strides=(2, 2))(f4)\n",
    "\n",
    "    f8 = bottleneck_block(x, num_channels, hgname + 'l8')\n",
    "\n",
    "    return (f1, f2, f4, f8)\n",
    "\n",
    "def left_to_right(left, right, name, num_channels):\n",
    "    \n",
    "    xleft = bottleneck_block(left, num_channels, name + 'connect')\n",
    "    xright = UpSampling2D()(right)\n",
    "    add = Add()([xleft, xright])\n",
    "    out = bottleneck_block(add, num_channels, name + 'connect_conv')\n",
    "    return out\n",
    "\n",
    "def bottom_layer(lf8, hgid, num_channels):\n",
    "    \n",
    "    lf8_connect = bottleneck_block(lf8, num_channels, str(hgid) + \"lf8\")\n",
    "\n",
    "    x = bottleneck_block(lf8, num_channels, str(hgid) + \"lf8_x1\")\n",
    "    x = bottleneck_block(x, num_channels, str(hgid) + \"lf8_x2\")\n",
    "    x = bottleneck_block(x, num_channels, str(hgid) + \"lf8_x3\")\n",
    "\n",
    "    rf8 = Add()([x, lf8_connect])\n",
    "\n",
    "    return rf8\n",
    "\n",
    "def right_half_blocks(leftfeatures, hglayer, num_channels):  #branch_add\n",
    "    lf1, lf2, lf4, lf8 = leftfeatures\n",
    "\n",
    "    rf8 = bottom_layer(lf8, hglayer, num_channels)\n",
    "\n",
    "    rf4 = left_to_right(lf4, rf8, 'hg' + str(hglayer) + 'rf4', num_channels)\n",
    "\n",
    "    rf2 = left_to_right(lf2, rf4, 'hg' + str(hglayer) + 'rf2', num_channels)\n",
    "\n",
    "    rf1 = left_to_right(lf1, rf2, 'hg' + str(hglayer) + 'rf1', num_channels)\n",
    "\n",
    "    return rf1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cosine Schehduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "import math\n",
    "\n",
    "class CosineAnnealingWarmup(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, epochs_per_cycle,iteration, max_lr, min_lr, verbose = 1):\n",
    "        self.epochs_per_cycle = epochs_per_cycle\n",
    "        self.max_lr = max_lr\n",
    "        self.min_lr = min_lr\n",
    "        self.iteration = iteration;\n",
    "        self.steps = 0;\n",
    "        self.learning_rate = max_lr;\n",
    "        self.epochs = 0; # epoch to search min_lr for each iteration \n",
    "        self.warmup_epoch = 10  # warmup epcch\n",
    "        self.verbose = verbose # log\n",
    "        self.lrates = list() # for graph\n",
    "        \n",
    "        \n",
    "    def cosine_annealing(self, epoch, epochs_per_cycle, max_lr):\n",
    "        self.epochs += 1; \n",
    "        cos_inner = (math.pi * (self.epochs % epochs_per_cycle)) / (epochs_per_cycle)\n",
    "        self.learning_rate = max_lr/2 * (math.cos(cos_inner) + 1)\n",
    "        \n",
    "        if ((self.epochs % epochs_per_cycle) == (epochs_per_cycle-1)):\n",
    "            self.steps += 1\n",
    "            self.max_lr *= 0.8\n",
    "            self.epochs = 0;\n",
    "            self.epochs_per_cycle = math.floor(self.epochs_per_cycle*1.2)\n",
    "            \n",
    "        return max_lr/2 * (math.cos(cos_inner) + 1)\n",
    "  \n",
    "    def warm_up(self, epoch):\n",
    "        \n",
    "        self.learning_rate = self.max_lr * epoch / self.warmup_epoch\n",
    "        \n",
    "        return self.learning_rate\n",
    "\n",
    "    # calculate and set learning rate at the start of the epoch\n",
    "    def on_epoch_begin(self, epoch, logs = None):\n",
    "        if (epoch < self.warmup_epoch):\n",
    "            # warm up learning rate\n",
    "            lr = self.warm_up(epoch)\n",
    "       \n",
    "        elif(self.steps < self.iteration):\n",
    "            # calculate learning rate\n",
    "            lr = self.cosine_annealing(epoch, self.epochs_per_cycle, self.max_lr)\n",
    "            \n",
    "        else:\n",
    "            lr = self.min_lr\n",
    "        \n",
    "#         if (self.verbose == 1):\n",
    "#             print('\\nEpoch %05d: CosineAnnealingScheduler setting learng rate to %s.' % (epoch + 1, lr))  \n",
    "\n",
    "        \n",
    "        K.set_value(self.model.optimizer.lr, lr)\n",
    "\n",
    "        self.lrates.append(lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_schedule = CosineAnnealingWarmup(epochs_per_cycle=300, iteration=2,max_lr = 1e-3, min_lr = 1e-6)\n",
    "\n",
    "# for i in range(1, 1000 + 1):\n",
    "#     cosine_schedule.on_epoch_begin(i)\n",
    "    \n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.plot(cosine_schedule.lrates)\n",
    "# plt.title('Cosine Annealing_Toy')\n",
    "# plt.xlabel('epochs'); plt.ylabel('learning_rate')\n",
    "# plt.grid()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 180 samples, validate on 60 samples\n",
      "Epoch 1/50\n",
      "180/180 [==============================] - 31s 173ms/sample - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0241 - val_mse: 0.0241\n",
      "Epoch 2/50\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0226 - val_mse: 0.0226\n",
      "Epoch 3/50\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0164 - val_mse: 0.0164\n",
      "Epoch 4/50\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 5/50\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 6/50\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 7/50\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 8/50\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 9/50\n",
      "180/180 [==============================] - 2s 10ms/sample - loss: 0.0269 - mse: 0.0269 - val_loss: 3.7220 - val_mse: 3.7220\n",
      "Epoch 10/50\n",
      "180/180 [==============================] - 2s 10ms/sample - loss: 0.0170 - mse: 0.0170 - val_loss: 542.2215 - val_mse: 542.2216\n",
      "Epoch 11/50\n",
      "180/180 [==============================] - 2s 10ms/sample - loss: 0.0170 - mse: 0.0170 - val_loss: 304.1076 - val_mse: 304.1076\n",
      "Epoch 12/50\n",
      "180/180 [==============================] - 2s 10ms/sample - loss: 0.0170 - mse: 0.0170 - val_loss: 198.5932 - val_mse: 198.5932\n",
      "Epoch 13/50\n",
      "180/180 [==============================] - 2s 10ms/sample - loss: 0.0170 - mse: 0.0170 - val_loss: 76.1010 - val_mse: 76.1010\n",
      "Epoch 14/50\n",
      "180/180 [==============================] - 2s 10ms/sample - loss: 0.0170 - mse: 0.0170 - val_loss: 14.0575 - val_mse: 14.0575\n",
      "Epoch 15/50\n",
      "180/180 [==============================] - 2s 10ms/sample - loss: 0.0170 - mse: 0.0170 - val_loss: 5.1388 - val_mse: 5.1388\n",
      "Epoch 16/50\n",
      "180/180 [==============================] - 2s 10ms/sample - loss: 0.0170 - mse: 0.0170 - val_loss: 2.3628 - val_mse: 2.3628\n",
      "Epoch 17/50\n",
      "180/180 [==============================] - 2s 10ms/sample - loss: 0.0169 - mse: 0.0169 - val_loss: 1.2107 - val_mse: 1.2107\n",
      "Epoch 18/50\n",
      "180/180 [==============================] - 2s 10ms/sample - loss: 0.0169 - mse: 0.0169 - val_loss: 0.4458 - val_mse: 0.4458\n",
      "Epoch 19/50\n",
      "180/180 [==============================] - 2s 10ms/sample - loss: 0.0169 - mse: 0.0169 - val_loss: 0.5251 - val_mse: 0.5251\n",
      "Epoch 20/50\n",
      "180/180 [==============================] - 2s 10ms/sample - loss: 0.0169 - mse: 0.0169 - val_loss: 0.5939 - val_mse: 0.5939\n",
      "Epoch 21/50\n",
      "180/180 [==============================] - 2s 10ms/sample - loss: 0.0169 - mse: 0.0169 - val_loss: 0.5277 - val_mse: 0.5277\n",
      "Epoch 22/50\n",
      "180/180 [==============================] - 2s 10ms/sample - loss: 0.0169 - mse: 0.0169 - val_loss: 0.5247 - val_mse: 0.5247\n",
      "Epoch 23/50\n",
      "180/180 [==============================] - 2s 10ms/sample - loss: 0.0169 - mse: 0.0169 - val_loss: 0.5165 - val_mse: 0.5165\n",
      "Epoch 24/50\n",
      "180/180 [==============================] - 2s 10ms/sample - loss: 0.0169 - mse: 0.0169 - val_loss: 0.2854 - val_mse: 0.2854\n",
      "Epoch 25/50\n",
      "180/180 [==============================] - 2s 10ms/sample - loss: 0.0169 - mse: 0.0169 - val_loss: 0.1218 - val_mse: 0.1218\n",
      "Epoch 26/50\n",
      "180/180 [==============================] - 2s 10ms/sample - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0524 - val_mse: 0.0524\n",
      "Epoch 27/50\n",
      "180/180 [==============================] - 2s 10ms/sample - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0380 - val_mse: 0.0380\n",
      "Epoch 28/50\n",
      "180/180 [==============================] - 2s 10ms/sample - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0657 - val_mse: 0.0657\n",
      "Epoch 29/50\n",
      "180/180 [==============================] - 2s 10ms/sample - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0712 - val_mse: 0.0712\n",
      "Epoch 30/50\n",
      "180/180 [==============================] - 2s 10ms/sample - loss: 0.0169 - mse: 0.0169 - val_loss: 0.1381 - val_mse: 0.1381\n",
      "Epoch 31/50\n",
      "180/180 [==============================] - 2s 10ms/sample - loss: 0.0169 - mse: 0.0169 - val_loss: 0.1126 - val_mse: 0.1126\n",
      "Epoch 32/50\n",
      "180/180 [==============================] - 2s 10ms/sample - loss: 0.0169 - mse: 0.0169 - val_loss: 0.1010 - val_mse: 0.1010\n",
      "Epoch 33/50\n",
      "180/180 [==============================] - 2s 10ms/sample - loss: 0.0169 - mse: 0.0169 - val_loss: 0.1433 - val_mse: 0.1433\n",
      "Epoch 34/50\n",
      "180/180 [==============================] - 2s 10ms/sample - loss: 0.0169 - mse: 0.0169 - val_loss: 0.1181 - val_mse: 0.1181\n",
      "Epoch 35/50\n",
      "180/180 [==============================] - 2s 10ms/sample - loss: 0.0169 - mse: 0.0169 - val_loss: 0.1321 - val_mse: 0.1321\n",
      "Epoch 36/50\n",
      "180/180 [==============================] - 2s 10ms/sample - loss: 0.0169 - mse: 0.0169 - val_loss: 0.1632 - val_mse: 0.1632\n",
      "Epoch 37/50\n",
      "180/180 [==============================] - 2s 10ms/sample - loss: 0.0169 - mse: 0.0169 - val_loss: 0.1412 - val_mse: 0.1412\n",
      "Epoch 38/50\n",
      "180/180 [==============================] - 2s 10ms/sample - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0637 - val_mse: 0.0637\n",
      "Epoch 39/50\n",
      "180/180 [==============================] - 2s 10ms/sample - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0248 - val_mse: 0.0248\n",
      "Epoch 40/50\n",
      "180/180 [==============================] - 2s 10ms/sample - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0222 - val_mse: 0.0222\n",
      "Epoch 41/50\n",
      "180/180 [==============================] - 2s 10ms/sample - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 42/50\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 43/50\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 44/50\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 45/50\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 46/50\n",
      "180/180 [==============================] - 2s 10ms/sample - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 47/50\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 48/50\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 49/50\n",
      "180/180 [==============================] - 2s 10ms/sample - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 50/50\n",
      "180/180 [==============================] - 2s 11ms/sample - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0130 - val_mse: 0.0130\n"
     ]
    }
   ],
   "source": [
    "# Load Data\n",
    "image_array = np.load('/home/hackerton/jupyter/Pain_data/image.npy')\n",
    "label_array = np.load('/home/hackerton/jupyter/Pain_data/label.npy').reshape(-1, 16)\n",
    "\n",
    "# Normalization\n",
    "X_train = image_array[:180] / 255\n",
    "y_train = label_array[:180] / 512\n",
    "\n",
    "X_valid = image_array[180:240] / 255\n",
    "y_valid = label_array[180:240] / 512\n",
    "\n",
    "gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "strategy = tf.distribute.MirroredStrategy([gpu.name for gpu in gpus])\n",
    "\n",
    "with strategy.scope():\n",
    "    model = hourglass_network(input_shape=(512, 512, 1), num_classes=16, num_stacks=1, num_channels=32)\n",
    "    model.compile(loss=tf.keras.losses.mean_squared_error , optimizer=tf.keras.optimizers.Adam(lr=0.001 ) , metrics=['mse'])\n",
    "    model.load_weights('/home/hackerton/jupyter/Pain_data/check/pain_final.h5')\n",
    "# Call Back\n",
    "monitor = 'val_loss'\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor=monitor, factor=0.1, patience=12, min_lr=0.0000001,verbose=1)\n",
    "earlystopper = EarlyStopping(monitor=monitor, patience=50, verbose=1,restore_best_weights=True)\n",
    "# model_checkpoint = ModelCheckpoint(filepath = '../result/model_save/landmark_model_1.h5', verbose=1, save_best_only=True)\n",
    "\n",
    "# callbacks_list = [reduce_lr, model_checkpoint, earlystopper]\n",
    "callbacks_list = [cosine_schedule, earlystopper]\n",
    "\n",
    "# Train\n",
    "history = model.fit(X_train, y_train, batch_size=16, epochs=50, shuffle=True, verbose=1, \n",
    "               validation_data=(X_valid, y_valid), callbacks=callbacks_list)\n",
    "\n",
    "\n",
    "model.save('/home/hackerton/jupyter/Pain_data/check/pain_final.h5')\n",
    "\n",
    "# Predict\n",
    "\n",
    "pred = model.predict(X_valid)\n",
    "\n",
    "\n",
    "# Save Prediction\n",
    "np.save('/home/hackerton/jupyter/Pain_data/predict.npy', pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Training and Validation mse')"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mse = history.history['mse']\n",
    "val_mse = history.history['mse']\n",
    "\n",
    "epochs_range = range(len(history.history['mse']))\n",
    " \n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.plot(epochs_range, mse, label='Training mse')\n",
    "plt.plot(epochs_range, val_mse, label='Validation mse')\n",
    "plt.ylim([0, 0.5])\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation mse')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2514b4188b6e46479ad745ed02c2cad1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=60), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Point 1 Distance Error:  40.774  ±  34.426      (mm)\n",
      "Point 2 Distance Error:  40.949  ±  34.296      (mm)\n",
      "Point 3 Distance Error:  52.832  ±  40.492      (mm)\n",
      "Point 4 Distance Error:  52.989  ±  40.429      (mm)\n",
      "Point 5 Distance Error:  41.908  ±  28.424      (mm)\n",
      "Point 6 Distance Error:  41.983  ±  28.509      (mm)\n",
      "Point 7 Distance Error:  64.41  ±  62.526      (mm)\n",
      "Point 8 Distance Error:  64.845  ±  62.198      (mm)\n"
     ]
    }
   ],
   "source": [
    "# 딥러닝 모델 결과 검증코드\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "point_1_distance_error = []\n",
    "point_2_distance_error = []\n",
    "point_3_distance_error = []\n",
    "point_4_distance_error = []\n",
    "point_5_distance_error = []\n",
    "point_6_distance_error = []\n",
    "point_7_distance_error = []\n",
    "point_8_distance_error = []\n",
    "\n",
    "\n",
    "original_size_label = np.zeros((60, 8, 2))\n",
    "\n",
    "\n",
    "predict = np.load('/home/hackerton/jupyter/Pain_data/predict.npy')\n",
    "label = np.load('/home/hackerton/jupyter/Pain_data/label.npy')[180:]\n",
    "\n",
    "file_name = np.load('/home/hackerton/jupyter/Pain_data/file_name.npy')[180:]\n",
    "reduce_ratio = np.load('/home/hackerton/jupyter/Pain_data/reduce_ratio.npy')[180:]\n",
    "pixel_spacing = np.load('/home/hackerton/jupyter/Pain_data/pixel_spacing.npy')[180:]\n",
    "\n",
    "\n",
    "original_size_predict = predict * 512\n",
    "original_size_predict = original_size_predict.reshape(60, 8, 2)\n",
    "\n",
    "\n",
    "for i in tqdm_notebook(range(predict.shape[0])):\n",
    "\n",
    "    x_reduce_ratio = reduce_ratio[i][0]\n",
    "    y_reduce_ratio = reduce_ratio[i][1]\n",
    "\n",
    "    original_size_label[i][:, 0] = label[i][:, 0] / x_reduce_ratio\n",
    "    original_size_label[i][:, 1] = label[i][:, 1] / y_reduce_ratio\n",
    "\n",
    "    original_size_predict[i][:,0] = original_size_predict[i][:, 0] / x_reduce_ratio\n",
    "    original_size_predict[i][:,1] = original_size_predict[i][:, 1] / y_reduce_ratio\n",
    "\n",
    "    point_1_distance_error.append(pixel_spacing[i][0] * np.sqrt((original_size_label[i][:, 0][0] - original_size_predict[i]\n",
    "                                                                 [:, 0][0])**2 + (original_size_label[i][:, 1][0] - original_size_predict[i][:, 1][0])**2))\n",
    "    point_2_distance_error.append(pixel_spacing[i][0] * np.sqrt((original_size_label[i][:, 0][1] - original_size_predict[i]\n",
    "                                                                 [:, 0][1])**2 + (original_size_label[i][:, 1][1] - original_size_predict[i][:, 1][1])**2))\n",
    "    point_3_distance_error.append(pixel_spacing[i][0] * np.sqrt((original_size_label[i][:, 0][2] - original_size_predict[i]\n",
    "                                                                 [:, 0][2])**2 + (original_size_label[i][:, 1][2] - original_size_predict[i][:, 1][2])**2))\n",
    "    point_4_distance_error.append(pixel_spacing[i][0] * np.sqrt((original_size_label[i][:, 0][3] - original_size_predict[i]\n",
    "                                                                 [:, 0][3])**2 + (original_size_label[i][:, 1][3] - original_size_predict[i][:, 1][3])**2))\n",
    "\n",
    "    point_5_distance_error.append(pixel_spacing[i][0] * np.sqrt((original_size_label[i][:, 0][4] - original_size_predict[i]\n",
    "                                                                 [:, 0][4])**2 + (original_size_label[i][:, 1][4] - original_size_predict[i][:, 1][4])**2))\n",
    "    point_6_distance_error.append(pixel_spacing[i][0] * np.sqrt((original_size_label[i][:, 0][5] - original_size_predict[i]\n",
    "                                                                 [:, 0][5])**2 + (original_size_label[i][:, 1][5] - original_size_predict[i][:, 1][5])**2))\n",
    "    point_7_distance_error.append(pixel_spacing[i][0] * np.sqrt((original_size_label[i][:, 0][6] - original_size_predict[i]\n",
    "                                                                 [:, 0][6])**2 + (original_size_label[i][:, 1][6] - original_size_predict[i][:, 1][6])**2))\n",
    "    point_8_distance_error.append(pixel_spacing[i][0] * np.sqrt((original_size_label[i][:, 0][7] - original_size_predict[i]\n",
    "                                                                 [:, 0][7])**2 + (original_size_label[i][:, 1][7] - original_size_predict[i][:, 1][7])**2))\n",
    "\n",
    "\n",
    "point_1_mean, point_1_std = np.round(\n",
    "    np.mean(point_1_distance_error), 3), np.round(np.std(point_1_distance_error), 3)\n",
    "point_2_mean, point_2_std = np.round(\n",
    "    np.mean(point_2_distance_error), 3), np.round(np.std(point_2_distance_error), 3)\n",
    "point_3_mean, point_3_std = np.round(\n",
    "    np.mean(point_3_distance_error), 3), np.round(np.std(point_3_distance_error), 3)\n",
    "point_4_mean, point_4_std = np.round(\n",
    "    np.mean(point_4_distance_error), 3), np.round(np.std(point_4_distance_error), 3)\n",
    "\n",
    "\n",
    "point_5_mean, point_5_std = np.round(\n",
    "    np.mean(point_5_distance_error), 3), np.round(np.std(point_5_distance_error), 3)\n",
    "point_6_mean, point_6_std = np.round(\n",
    "    np.mean(point_6_distance_error), 3), np.round(np.std(point_6_distance_error), 3)\n",
    "point_7_mean, point_7_std = np.round(\n",
    "    np.mean(point_7_distance_error), 3), np.round(np.std(point_7_distance_error), 3)\n",
    "point_8_mean, point_8_std = np.round(\n",
    "    np.mean(point_8_distance_error), 3), np.round(np.std(point_8_distance_error), 3)\n",
    "\n",
    "\n",
    "print('Point 1 Distance Error: ', point_1_mean, ' ± ', point_1_std, '     (mm)')\n",
    "print('Point 2 Distance Error: ', point_2_mean, ' ± ', point_2_std, '     (mm)')\n",
    "print('Point 3 Distance Error: ', point_3_mean, ' ± ', point_3_std, '     (mm)')\n",
    "print('Point 4 Distance Error: ', point_4_mean, ' ± ', point_4_std, '     (mm)')\n",
    "\n",
    "print('Point 5 Distance Error: ', point_5_mean, ' ± ', point_5_std, '     (mm)')\n",
    "print('Point 6 Distance Error: ', point_6_mean, ' ± ', point_6_std, '     (mm)')\n",
    "print('Point 7 Distance Error: ', point_7_mean, ' ± ', point_7_std, '     (mm)')\n",
    "print('Point 8 Distance Error: ', point_8_mean, ' ± ', point_8_std, '     (mm)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0509353645524ed2818fbf165e7a9bdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=60), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Line 1 R2 Score:  -4.851438379567778\n",
      "Line 2 R2 Score:  -2.4432105169579024\n",
      "Line 3 R2 Score:  -3.110664328217755\n",
      "Line 4 R2 Score:  -2.2087769563873225\n"
     ]
    }
   ],
   "source": [
    "# 측정된 거리 검증 코드\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "label_line_1 = []\n",
    "label_line_2 = []\n",
    "label_line_3 = []\n",
    "label_line_4 = []\n",
    "\n",
    "pred_line_1 = []\n",
    "pred_line_2 = []\n",
    "pred_line_3 = []\n",
    "pred_line_4 = []\n",
    "\n",
    "original_size_label = np.zeros((60, 8, 2))\n",
    "\n",
    "\n",
    "# predict = np.load('/home/hackerton/jupyter/Pain_data/predict.npy')\n",
    "# label = np.load('/home/hackerton/jupyter/Pain_data/label.npy')[240:]\n",
    "\n",
    "\n",
    "# reduce_ratio = np.load('/home/hackerton/jupyter/Pain_data/reduce_ratio.npy')[240:]\n",
    "# pixel_spacing = np.load('/home/hackerton/jupyter/Pain_data/pixel_spacing.npy')[240:]\n",
    "\n",
    "\n",
    "\n",
    "original_size_predict = predict * 512\n",
    "original_size_predict = original_size_predict.reshape(60, 8, 2)\n",
    "\n",
    "\n",
    "for i in tqdm_notebook(range(predict.shape[0])):\n",
    "\n",
    "    x_reduce_ratio = reduce_ratio[i][0]\n",
    "    y_reduce_ratio = reduce_ratio[i][1]\n",
    "\n",
    "    original_size_label[i][:, 0] = label[i][:, 0] / x_reduce_ratio\n",
    "    original_size_label[i][:, 1] = label[i][:, 1] / y_reduce_ratio\n",
    "\n",
    "    original_size_predict[i][:,0] = original_size_predict[i][:, 0] / x_reduce_ratio\n",
    "    original_size_predict[i][:,1] = original_size_predict[i][:, 1] / y_reduce_ratio\n",
    "\n",
    "    label_line_1.append(np.round(pixel_spacing[i][0] * np.sqrt((original_size_label[i][0][0] -\n",
    "                                                                original_size_label[i][1][0])**2 + (original_size_label[i][0][1] - original_size_label[i][1][1])**2), 3))\n",
    "    label_line_2.append(np.round(pixel_spacing[i][0] * np.sqrt((original_size_label[i][2][0] -\n",
    "                                                                original_size_label[i][3][0])**2 + (original_size_label[i][2][1] - original_size_label[i][3][1])**2), 3))\n",
    "    label_line_3.append(np.round(pixel_spacing[i][0] * np.sqrt((original_size_label[i][4][0] -\n",
    "                                                                original_size_label[i][5][0])**2 + (original_size_label[i][4][1] - original_size_label[i][5][1])**2), 3))\n",
    "    label_line_4.append(np.round(pixel_spacing[i][0] * np.sqrt((original_size_label[i][6][0] -\n",
    "                                                                original_size_label[i][7][0])**2 + (original_size_label[i][6][1] - original_size_label[i][7][1])**2), 3))\n",
    "\n",
    "    pred_line_1.append(np.round(pixel_spacing[i][0] * np.sqrt((original_size_predict[i][0][0] - original_size_predict[i][1][0])**2 + (\n",
    "        original_size_predict[i][0][1] - original_size_predict[i][1][1])**2), 3))\n",
    "    pred_line_2.append(np.round(pixel_spacing[i][0] * np.sqrt((original_size_predict[i][2][0] - original_size_predict[i][3][0])**2 + (\n",
    "        original_size_predict[i][2][1] - original_size_predict[i][3][1])**2), 3))\n",
    "    pred_line_3.append(np.round(pixel_spacing[i][0] * np.sqrt((original_size_predict[i][4][0] - original_size_predict[i][5][0])**2 + (\n",
    "        original_size_predict[i][4][1] - original_size_predict[i][5][1])**2), 3))\n",
    "    pred_line_4.append(np.round(pixel_spacing[i][0] * np.sqrt((original_size_predict[i][6][0] - original_size_predict[i][7][0])**2 + (\n",
    "        original_size_predict[i][6][1] - original_size_predict[i][7][1])**2), 3))\n",
    "\n",
    "print('Line 1 R2 Score: ',r2_score(label_line_1, pred_line_1))\n",
    "print('Line 2 R2 Score: ',r2_score(label_line_2, pred_line_2))\n",
    "print('Line 3 R2 Score: ',r2_score(label_line_3, pred_line_3))\n",
    "print('Line 4 R2 Score: ',r2_score(label_line_4, pred_line_4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line 1 Distance Error:  4.091  ±  1.861      (mm)\n",
      "Line 2 Distance Error:  2.454  ±  1.422      (mm)\n",
      "Line 3 Distance Error:  3.31  ±  1.868      (mm)\n",
      "Line 4 Distance Error:  3.101  ±  1.783      (mm)\n"
     ]
    }
   ],
   "source": [
    "line_1_distance_error_mean, line_1_distance_error_std = np.round(np.mean(np.abs(np.array(\n",
    "    label_line_1) - np.array(pred_line_1))), 3), np.round(np.std(np.abs(np.array(label_line_1) - np.array(pred_line_1))), 3)\n",
    "line_2_distance_error_mean, line_2_distance_error_std = np.round(np.mean(np.abs(np.array(\n",
    "    label_line_2) - np.array(pred_line_2))), 3), np.round(np.std(np.abs(np.array(label_line_2) - np.array(pred_line_2))), 3)\n",
    "line_3_distance_error_mean, line_3_distance_error_std = np.round(np.mean(np.abs(np.array(\n",
    "    label_line_3) - np.array(pred_line_3))), 3), np.round(np.std(np.abs(np.array(label_line_3) - np.array(pred_line_3))), 3)\n",
    "line_4_distance_error_mean, line_4_distance_error_std = np.round(np.mean(np.abs(np.array(\n",
    "    label_line_4) - np.array(pred_line_4))), 3), np.round(np.std(np.abs(np.array(label_line_4) - np.array(pred_line_4))), 3)\n",
    "\n",
    "\n",
    "print('Line 1 Distance Error: ', line_1_distance_error_mean,\n",
    "      ' ± ', line_1_distance_error_std, '     (mm)')\n",
    "print('Line 2 Distance Error: ', line_2_distance_error_mean,\n",
    "      ' ± ', line_2_distance_error_std, '     (mm)')\n",
    "print('Line 3 Distance Error: ', line_3_distance_error_mean,\n",
    "      ' ± ', line_3_distance_error_std, '     (mm)')\n",
    "print('Line 4 Distance Error: ', line_4_distance_error_mean,\n",
    "      ' ± ', line_4_distance_error_std, '     (mm)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
